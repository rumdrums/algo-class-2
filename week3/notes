Data Structures
. eg, lists, stacks, queues, heaps, search trees, hash tables,
  bloom filters, union-find
. different structures support different sets of
  operations
. fewer operations a structure supports, the faster the operations
  will be, and the smaller amount of memory required

Heaps
. operations:
  -- insertion -- add a new object
     -- O(log n)
  -- extract min -- remove an object in heap with a minimum key value 
     ( ties are broken arbitrarily ); there can also be extract max 
     operations, but not in same heap
     -- O(log n)
 -- heapify -- initialize a heap with a BATCH of
    objects in linear time
 -- delete (O(log n))
. container for objects that have keys;
  keys can be compared to one another
. canonical uses:
  -- your program is doing repetitive minimum computations
     using brute-force search --> SORTING!

Heap Sort
1) insert all n array elements into a heap
2) Extract-min to pluck out elements in sorted order
  -- O(n log n)
  -- optimal for a comparison-based sorting algorithm
  -- not quite as good as quicksort

Applications of Heaps
. "Priority queues" for Event Managers
 -- time stamp is the key
 -- extract-min yields the next scheduled event
. "Median maintenance"
 -- given a sequence of numbers, find median
    of subsets of the list (eg, median of first 2, median of first 3, median of first 4,
    etc)
 -- use 2 heaps
  -- smallest half of numbers in first heap
  -- largest half in second heap
  -- median is either largest of first, smallest of 2nd, or both
  -- periodically may have to move items between
     heaps to maintain balance
. Dijkstra

Implementation of Heaps
. best thought of as binary trees,
  but best implemented as __array__
 -- just go through the heap starting at level 0,
    left to right, adding items to array
 -- parent node of element i is:
     i/2 if i is even
     floor(i/2) if i is odd
 -- children of i:
    2i, 2i+1

. Insert -- done in logarithmic_2 time
 1) make the new key you're inserting the last leaf at the last level
 2) "Bubble" up until heap property is restored

. Extract-Min -- done in logarithmic_2 time
 1) "extract" root and delete it
 2) Move LAST LEAF to be new root -- this will likely result in lots
    of heap violations, so...
 3) Iteratively "Bubble Down" so that we again meet criterion that
    all keys are <= their children
    -- Bubble down as needed by replacing the root with the SMALLER
       of its children

Balanced Search Trees
 -- act like a sorted array, with fast operations for inserts and deletes
 -- needed for dynamic data structures -- if data static, just use sorted array
. SEARCH: O(log n)
. SELECT: O(log n)
. MIN/MAX: O(log n)
. PRED/SUCC (PREDECESSSOR/SUCCESSOR): O(log n)
. OUTPUT IN SORTED ORDER: O(n)
. RANK: O(log n)
. INSERT: O(log n)
. DELETE: O(log n)

Structure of a search tree
. Assume 3 pointers -- 1 to parent, 1 to left/right child each, may be null
. SEARCH TREE PROPERTY
 -- if node x has a key value, all keys in left subtree < x, all keys in right subtree > x
 -- there can be duplicate keys, just need convention for how handle 'ties'
 -- helps with fast SEARCHING, which is the whole point
. many possible trees for a given set of keys
 -- Height, then, can vary from ideal case of height = log_2n to height = n-1 (single node in each level)
. to search:
  -- start at root, recurse left or right if desired key is larger or smaller;
     return pointer, may be null
. to insert:
  -- do a search, which will fail (assuming no duplicates); set
     the null pointer to desired value



